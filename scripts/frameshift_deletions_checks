#!/usr/bin/env python3

import pysam
import pysamstats
import numpy as np
import pandas as pd
import os
from Bio import SeqIO
from BCBio import GFF
import argparse
import pandas as pd



def parse_args():
    """ Set up the parsing of command-line arguments """
    parser = argparse.ArgumentParser(
            description="Script to construct consensus sequences",
            formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    requiredNamed = parser.add_argument_group('required named arguments')
    requiredNamed.add_argument(
        "-i", required=True, metavar='BAM', dest='bamfile',
        help="Input BAM file"
    )
    parser.add_argument(
        "-c", required=True, metavar='FASTA', dest='ref_majority_dels', type=str,
        help="Fasta file containing the ref_majority_dels consensus sequence"
    )
    parser.add_argument(
        "-f", required=True, metavar='FASTA', dest='reference', type=str,
        help="Fasta file containing the reference sequence"
    )
    parser.add_argument(
        "-g", required=True, metavar='GFF', dest='genes_gff', type=str,
        help="GFF file listing genes positions on the reference sequence"
    )
    parser.add_argument(
        "-0", required=False, dest='based', action='store_const', const=0, default=1,
        help="Use 0-based (python) instead of 1-based (standard) seq positions"
    )
    parser.add_argument(
        "-o", required=False, default=os.path.join(os.getcwd(), 'frameshift_deletions_check.csv'),
        metavar='CSV', dest='outfile', help="Output file"
    )
    return parser.parse_args()

def check_homopolyeric(variation_info, position, gap_length):
    '''
    return homopolyeric == True if either around the start_position or the end_position
    between the two neighbors 3 are of the same base, eg. AATAG
    '''
    list =[]
    idx_pos = np.where(variation_info.pos ==position-1)[0]
    list.append(variation_info[idx_pos-2].ref[0])
    list.append(variation_info[idx_pos-1].ref[0])
    list.append(variation_info[idx_pos].ref[0])
    list.append(variation_info[idx_pos+1].ref[0])
    list.append(variation_info[idx_pos+2].ref[0])
    uni_list = np.unique(list, return_counts=True)
    if np.max(uni_list[1])>2:
        return 1
    else:
        #check end region of gap
        list =[]
        idx_pos = np.where(variation_info.pos ==position+gap_length-1)[0]
        list.append(variation_info[idx_pos-2].ref[0])
        list.append(variation_info[idx_pos-1].ref[0])
        list.append(variation_info[idx_pos].ref[0])
        list.append(variation_info[idx_pos+1].ref[0])
        list.append(variation_info[idx_pos+2].ref[0])
        uni_list = np.unique(list, return_counts=True)
        if np.max(uni_list[1])>2:
            return 1
        else:
            return 0

def parse_gff(genes_gff):
    """
    Return a gene_list suitable for get_gene_at_position
    """
    if genes_gff:
        with open(genes_gff) as gf:
            return [ (record.id, int(feature.location.start), int(feature.location.end), feature.qualifiers.get('Name', [feature.id])[0]) for record in GFF.parse(gf) for feature in record.features if feature.type == 'gene' ]
    return None

def get_gene_at_position(gene_list, ref_id, position):
    """
    Return gene and gene-region-interval the position belongs to.
    This is only valid for SARS-CoV2.
    """
    for gene in gene_list:
        if (gene[0] == ref_id) and (position in range(gene[1],gene[2])):
            return gene

    return (ref_id, position-10, position+10, '-')

def check_indels_gene_region(gene_reg_load_variation, region_start, region_end, coverage):
    """
    check if there are some indels in the gene-region-interval(*) that occur in
    more than 40% of the reads. If so, returns the position of those insertions.
    ---
    (*): or at least the part that got coverage
    """
    i_start = np.where(gene_reg_load_variation.pos >=region_start)[0][0]
    i_end = np.where(gene_reg_load_variation.pos <=region_end)[0][-1]

    inserts= gene_reg_load_variation.insertions[i_start:i_end]
    dels= gene_reg_load_variation.deletions[i_start:i_end]

    critical_inserts = [gene_reg_load_variation.pos[i] for i,x in enumerate(inserts) if x > 0.4*coverage]
    critical_dels = [item for item in dels if item > 0.4*coverage]

    return critical_inserts, critical_dels

def ranges(nums):
    """
    auxiliary function for list_frameshift_dels().
    Input is a list of numbers
    return ranges that are covered by those numbers,
    e.g. [1,2,3,10]--> [(1,3),(10,10)]
    """
    nums = sorted(set(nums))
    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]
    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])
    return list(zip(edges, edges))

def len_del(item_range):
    """
    auxiliary function for list_frameshift_dels().
    computing the lenght of item_range,
    """
    return item_range[1]- item_range[0]+1

def list_frameshift_inserts(aligned_seqs):
    '''
    returns list with starting position of frameshift_inserts and their resepective length as tuple: (start_pos, length)
    '''
    consensus_seq = aligned_seqs[1]
    reference_seq = aligned_seqs[0]
    pos_length_list = []
    insert_pos = [i for i,x in enumerate(reference_seq.seq) if x =="-"]

    for item_range in ranges(insert_pos):
            # only frameshift insertions , i.e. insert lenght not dividible by 3
            if len_del(item_range)%3 !=0:
                pos_length_list.append([item_range[0],len_del(item_range), reference_seq.id, consensus_seq.id, 'insertion'])

    return pos_length_list

def list_frameshift_dels(aligned_seqs):
    '''
    returns list with starting position of frameshift_dels and their resepective length as tuple: (start_pos, length)
    '''
    consensus_seq = aligned_seqs[1]
    reference_seq = aligned_seqs[0]
    pos_length_list = []
    del_pos = [i for i,x in enumerate(consensus_seq.seq) if x =="-"]

    for item_range in ranges(del_pos):
            # only frameshift deletions , i.e. deletion lenght not dividible by 3
            if len_del(item_range)%3 !=0:
                pos_length_list.append([item_range[0],len_del(item_range),reference_seq.id, consensus_seq.id, 'deletion'])

    return pos_length_list

def align(reference, consensus):
    from Bio.Align.Applications import MafftCommandline
    from io import StringIO
    from Bio import AlignIO
    import tempfile

    with open(reference) as fp:
        ref_data=fp.read()
    with open(consensus) as fp:
        cons_data=fp.read()

    data=ref_data+"\n"+cons_data

    tmp = tempfile.NamedTemporaryFile()

    # Open the file for writing.
    with open(tmp.name, 'w') as f:
        f.write(data)
        f.seek(0)

    mafft_cline = MafftCommandline(input=tmp.name)
    stdout, stderr = mafft_cline()
    align = AlignIO.read(StringIO(stdout), "fasta")

    return align

def check_dels_gene_region(frameshift_deletions, region_start, region_end, position):
    """
    Check for deletions that are also in the consensus in this gene region.
    """
    critical_pos= []
    for pos1 in frameshift_deletions:
        if pos1[0] in range(region_start, region_end):
            if pos1[0]!=position:
                critical_pos.append(pos1[0])

    return critical_pos

def correct_positions(list_dels,list_inserts):
    '''
    Insertions shift the positions --> shift back to reference seq space
    Correct to zero-based (we need this for pysamstats).
    '''
    # correct deletions shifted due to insertions occuring before
    for count, insert in enumerate(list_inserts):
        for deletion in list_dels:
            if deletion[0] > insert[0]:
                deletion[0]-=1
    # shift insertions due to insertions occuring before
    for count, insert in enumerate(list_inserts):
        for j in range(count+1, len(list_inserts)):
            if list_inserts[j][0] > insert[0]:
                list_inserts[j][0]-= 1
    # shift inseritions to zero-based space
    for j in range(len(list_inserts)):
        list_inserts[j][0]-=1

    corrected_insert = list_inserts
    corrected_dels =list_dels

    return corrected_insert, corrected_dels

def analyse_position(bamfile, reference, ref_id, position, gap_length, gene_list, cons_id='', based=1):
    """
    gather information for current frameshift position.
    """
    gene_region= get_gene_at_position(gene_list, ref_id, position)
    region_start =gene_region[1]
    region_end = gene_region[2]

    #critical_dels = check_dels_gene_region(frameshift_deletions, region_start, region_end, position)

    variation_info = pysamstats.load_variation_strand(bamfile, fafile= reference,chrom=ref_id,
                                     start=position, end=position+gap_length)
    idx_pos = np.where(variation_info.pos ==position)

    reads_all = variation_info[idx_pos].reads_all[0]
    reads_fwd = variation_info[idx_pos].reads_fwd[0]
    reads_rev = variation_info[idx_pos].reads_rev[0]

    deletions = variation_info[idx_pos].deletions[0]
    freq_del = deletions/reads_all*100
    deletions_fwd = variation_info[idx_pos].deletions_fwd[0]
    freq_del_fwd = deletions_fwd/reads_fwd*100 if reads_fwd else 0
    deletions_rev = variation_info[idx_pos].deletions_rev[0]
    freq_del_rev = deletions_rev/reads_rev*100 if reads_rev else 0

    insertions = variation_info[idx_pos].insertions[0]
    freq_insert = insertions/reads_all*100
    insertions_fwd = variation_info[idx_pos].insertions_fwd[0]
    freq_insert_fwd = insertions_fwd/reads_fwd*100 if reads_fwd else 0
    insertions_rev = variation_info[idx_pos].insertions_rev[0]
    freq_insert_rev = insertions_rev/reads_rev*100 if reads_rev else 0

    indels_gene_reg = pysamstats.load_variation_strand(bamfile, fafile=reference,
                                                        chrom=ref_id,
                                                        start=region_start, end=region_end)
    critical_inserts, critical_dels= check_indels_gene_region(indels_gene_reg,
                                                    region_start, region_end, reads_all)

    homopolyeric = check_homopolyeric(variation_info, position, gap_length)

    dict = {'ref_id': ref_id,
            'start_position': position+based,
            'length': gap_length,
            'gene_region':gene_region[3],
            'reads_all': reads_all,
            'reads_fwd': reads_fwd,
            'reads_rev': reads_rev,
            'deletions': deletions,
            'freq_del': freq_del,
            'freq_del_fwd': freq_del_fwd ,
            'freq_del_rev':freq_del_rev,
            'deletions_fwd': deletions_fwd,
            'deletions_rev': deletions_rev,
            'insertions': insertions,
            'freq_del': freq_del,
            'freq_insert_fwd': freq_insert_fwd ,
            'freq_insert_rev':freq_insert_rev,
            'insertions_fwd': insertions_fwd,
            'insertions_rev': insertions_rev,
            'matches_ref': variation_info[idx_pos].matches[0],
            'pos_critical_inserts': critical_inserts,
            'pos_critical_dels': critical_dels,
            'homopolymeric': homopolyeric,
            'ref_base': variation_info[idx_pos].ref[0],
            'cons_id': cons_id,
           }

    return dict

def main():

    args = parse_args()
    bamfile = args.bamfile	    # e.g.: 'REF_aln_410130_171220eg29_H5.bam'
    reference = args.reference	# e.g.: '../references/NC_045512.2.fasta'
    consensus = args.ref_majority_dels	# e.g.: 'ref_majority_dels.fasta'

    gene_list = parse_gff(args.genes_gff) # e.g.: 'Genes_NC_045512.2.GFF3'

    df = pd.DataFrame(columns=('ref_id','start_position','length','INDEL','gene_region','reads_all',
                                'reads_fwd','reads_rev', 'deletions','freq_del',
                                'freq_del_fwd' ,'freq_del_rev','deletions_fwd',
                                'deletions_rev','insertions','freq_del','freq_insert_fwd','freq_insert_rev',
                                'insertions_fwd','insertions_rev','matches_ref','pos_critical_inserts',
                                'pos_critical_dels','homopolymeric','ref_base','cons_id'))


    algin_seqs = align(reference, consensus)
    list_dels= list_frameshift_dels(algin_seqs)
    list_inserts= list_frameshift_inserts(algin_seqs)

    corrected_insert, corrected_dels = correct_positions(list_dels,list_inserts)
    
    all_frame_del =[]

    for pos in corrected_dels+corrected_insert:
        ref_id = pos[2]
        position = int(pos[0])
        gap_length = int(pos[1])
        cons_id = pos[3]
        type = pos[4]
        pos_dict = analyse_position(bamfile, reference, ref_id, position, gap_length,
                                    gene_list,cons_id, based=args.based)
        pos_dict.update({'INDEL': type})
        df = df.append(pos_dict, ignore_index=True)

    df.to_csv(args.outfile)

if __name__ == '__main__':
    main()
