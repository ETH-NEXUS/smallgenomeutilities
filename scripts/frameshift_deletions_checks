#!/usr/bin/env python3

import pysam
import pysamstats
import numpy as np
import pandas as pd
from io import StringIO
from Bio import SeqIO
from Bio import AlignIO
from Bio.Align.Applications import MafftCommandline
from BCBio import GFF
import argparse
import re
import os
import tempfile
import sys



def parse_args():
    """ Set up the parsing of command-line arguments """

    # keep lines in epilog ; but keep the defaults in the list
    class Formatter(argparse.ArgumentDefaultsHelpFormatter, argparse.RawDescriptionHelpFormatter): pass

    parser = argparse.ArgumentParser(
        description="Produces a report about frameshifting indels in a consensus sequences",
        epilog=u"""columns signification:
	[gene_region]: Gene in which the deletion is found according to -g argument;
	[reads_all]: Total number of reads covering the indel;
	[reads_fwd]: Total nubmer of forward reads covering the indel;
	[reads_rev]: Total nubmer of reverse reads covering the indel;
	[deletions/insertions]: Number of reads supporting the deletion/insertion;
	[freq_del/freq_insert]: Fraction of reads supporting the deletion/insertion;
	[matches_ref]: number of reads that matche with the reference base;
	[pos_critical_inserts]: Start positions of insertions in the same gene_region that occur in > 40% of reads;
	[pos_critical_dels]: Start positions of deletions in the same gene_region that occur in > 40% of reads;
	[homopolymeric]: True if either around the start or end position of the deletion three bases are the same, which may have caused the polymerase to skip during reverse transcription of viral RNA to cDNA, e.g. AATAG;
	[ref_base]: base in the reference genome""",
        formatter_class=Formatter)
    requiredNamed = parser.add_argument_group('required named arguments')
    requiredNamed.add_argument(
        "-i", "--input", required=True, metavar='BAM', dest='bamfile',
        help="Input BAM file, aligned against the reference"
    )
    requiredNamed.add_argument(
        "-c", "--consensus", required=True, metavar='FASTA', dest='ref_majority_dels', type=str,
        help="Fasta file containing the ref_majority_dels consensus sequence"
    )
    requiredNamed.add_argument(
        "-f", "--reference", required=True, metavar='FASTA', dest='reference', type=str,
        help="Fasta file containing the reference sequence to compare against"
    )
    requiredNamed.add_argument(
        "-g", "--genes", required=True, metavar='GFF', dest='genes_gff', type=str,
        help="GFF file listing genes positions on the reference sequence"
    )
    parser.add_argument(
        "-0", "--zero-based", required=False, dest='based', action='store_const', const=0, default=1,
        help="Use 0-based (python) instead of 1-based (standard) seq positions"
    )
    parser.add_argument(
        "-o", "--output", required=False, default=os.path.join(os.getcwd(), 'frameshift_deletions_check.csv'),
        metavar='CSV', dest='outfile', help="Output file"
    )
    return parser.parse_args()

def check_homopolyeric(variation_info, position, gap_length):
    '''
    return homopolyeric == True if either around the start_position or the end_position
    between the two neighbors 3 are of the same base, eg. AATAG
    '''
    list =[]
    idx_pos = np.where(variation_info.pos ==position-1)[0]
    list.append(variation_info[idx_pos-2].ref[0])
    list.append(variation_info[idx_pos-1].ref[0])
    list.append(variation_info[idx_pos].ref[0])
    list.append(variation_info[idx_pos+1].ref[0])
    list.append(variation_info[idx_pos+2].ref[0])
    uni_list = np.unique(list, return_counts=True)
    if np.max(uni_list[1])>2:
        return 1
    else:
        #check end region of gap
        list =[]
        idx_pos = np.where(variation_info.pos ==position+gap_length-1)[0]
        list.append(variation_info[idx_pos-2].ref[0])
        list.append(variation_info[idx_pos-1].ref[0])
        list.append(variation_info[idx_pos].ref[0])
        list.append(variation_info[idx_pos+1].ref[0])
        list.append(variation_info[idx_pos+2].ref[0])
        uni_list = np.unique(list, return_counts=True)
        if np.max(uni_list[1])>2:
            return 1
        else:
            return 0

def parse_gff(genes_gff):
    """
    Return a gene_list suitable for get_gene_at_position
    """
    if genes_gff:
        with open(genes_gff) as gf:
            return [ (record.id, int(feature.location.start), int(feature.location.end), feature.qualifiers.get('Name', [feature.id])[0]) for record in GFF.parse(gf) for feature in record.features if feature.type == 'gene' ]
    return None

def get_gene_at_position(gene_list, ref_id, position):
    """
    Return gene and gene-region-interval the position belongs to.
    This is only valid for SARS-CoV2.
    """
    for gene in gene_list:
        if (gene[0] == ref_id) and (position in range(gene[1],gene[2])):
            return gene

    return (ref_id, position-10, position+10, '-')

def check_indels_gene_region(gene_reg_load_variation, curr_pos, gap_length, indel_type, region_start, region_end, based):
    """
    check if there are some indels in the gene-region-interval(*) that occur in
    more than 40% of the reads. If so, returns the position of those insertions.
    ---
    (*): or at least the part that got coverage
    """

    # clip the request to position for which we have information. Worse-case scenario: begins or ends with the indel
    i_start = np.where(gene_reg_load_variation.pos >=region_start)[0][0]
    i_end = np.where(gene_reg_load_variation.pos <=region_end)[0][-1]

    # NOTE the index of these scrutures will be same across all,
    # BUT will not correspond to the actual position
    indel_pos = gene_reg_load_variation.pos[i_start:i_end]
    reads_all = gene_reg_load_variation.reads_all[i_start:i_end]
    inserts= gene_reg_load_variation.insertions[i_start:i_end]
    dels= gene_reg_load_variation.deletions[i_start:i_end]

    # NOTE When looking for an insert:
    # - we will not list the insert *itself*
    # - we *will* list overlapping *deletions* on other reads.
    # And vice-versa for deletions.
    critical_inserts = [indel_pos[i]+based for i,x in enumerate(inserts) if (x > 0.4*reads_all[i]) and (indel_type=='deletion' or indel_pos[i]!=curr_pos)]
    critical_dels = [indel_pos[i]+based for i,x in enumerate(dels) if (x > 0.4*reads_all[i]) and ((indel_type=='insertion') or (indel_pos[i] not in range(curr_pos, curr_pos+gap_length)))]

    return critical_inserts, critical_dels

def ranges(nums):
    """
    auxiliary function for list_frameshift_dels().
    Input is a list of numbers
    return ranges that are covered by those numbers,
    e.g. [1,2,3,10]--> [(1,3),(10,10)]
    """
    nums = sorted(set(nums))
    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]
    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])
    return list(zip(edges, edges))

def len_del(item_range):
    """
    auxiliary function for list_frameshift_dels().
    computing the lenght of item_range,
    """
    return item_range[1]- item_range[0]+1

def list_all_inserts(aligned_seqs):
    '''
    returns list with starting position of _all_ inserts and their resepective length as tuple: (start_pos, length)
    '''
    pos_length_list = []
    for reference_seq, consensus_seq in zip(*[iter(aligned_seqs)]*2):
        insert_pos = [i for i,x in enumerate(reference_seq.seq) if x =="-"]

        for item_range in ranges(insert_pos):
            pos_length_list.append([item_range[0],len_del(item_range), reference_seq.id, consensus_seq.id, 'insertion'])

    return pos_length_list

def list_all_dels(aligned_seqs):
    '''
    returns list with starting position of _all_  dels and their resepective length as tuple: (start_pos, length)
    '''
    pos_length_list = []
    for reference_seq, consensus_seq in zip(*[iter(aligned_seqs)]*2):
        del_pos = [i for i,x in enumerate(consensus_seq.seq) if x =="-"]

        for item_range in ranges(del_pos):
            pos_length_list.append([item_range[0],len_del(item_range),reference_seq.id, consensus_seq.id, 'deletion'])

    return pos_length_list

def align(reference, consensus):
    """
    we rely on a MAFFT alignment, in order to:
    - detect deletions in consensuses from callers that do not mark them
      (e.g.: bcftools without the `--mark-dels '-'` option)
    - detect insertions in the consensus
        (will appear as deletions *in the reference*)
    """


    all_align=[]

    # Loop through pairs to avoid MAFFT aligning different unrelated segments
    for seq_record, ref_record in zip(SeqIO.parse(consensus, "fasta"), SeqIO.parse(reference, "fasta")):
        # HACK assume seq_record have same order as ref_record
        # TODO test to multi-segemented viruses before the next flu pandemic
        print(f"{seq_record.id} mapped to {ref_record.id}")

        if (align.rx_only_n.match(str(seq_record.seq))):
            print(f"Warning: {seq_record.id} contains only <N>s", file=sys.stderr)
            # BUG MAFFT has a bug where if such a only-<N>s sequence is given as an argument, it will generate an alignement offset by 1 bogus gap at each end:
            # > Alignment with 2 rows and 29904 columns
            # > attaaaggtttataccttcccaggtaacaaaccaaccaactttc...aa- NC_045512.2
            # > -nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn...nnn 100100_31_C02-20200508_J3GT6
            # these bogus gaps are not supported by any reads and break analyse_position()
            # we *must* not call MAFFT
            continue

        data=[ref_record, seq_record]

        # NOTE this also handles properly TMPDIR on clusters
        with tempfile.NamedTemporaryFile() as tmp:
            # Open the file for writing.
            with open(tmp.name, 'w') as f:
                SeqIO.write(data, tmp.name, "fasta")
                f.seek(0)

            mafft_cline = MafftCommandline(input=tmp.name)
            stdout, stderr = mafft_cline()
            if (len(stderr)>0):
                print(mafft_cline, ":", file=sys.stderr)
                print(stderr, file=sys.stderr)
            all_align += AlignIO.read(StringIO(stdout), "fasta")

    return all_align
# static re: only compile it once
align.rx_only_n=re.compile("^[Nn]+$")

def check_dels_gene_region(frameshift_deletions, region_start, region_end, position):
    """
    Check for deletions that are also in the consensus in this gene region.
    """
    critical_pos= []
    for pos1 in frameshift_deletions:
        if pos1[0] in range(region_start, region_end):
            if pos1[0]!=position:
                critical_pos.append(pos1[0])

    return critical_pos

def correct_positions(list_dels,list_inserts):
    '''
    Insertions shift the positions --> shift back to reference seq space
    Correct to zero-based (we need this for pysamstats).
    '''
    # correct deletions shifted due to insertions occuring before
    for count, insert in enumerate(list_inserts):
        for deletion in list_dels:
            if deletion[0] > insert[0]:
                deletion[0]-=insert[1]
    # shift insertions due to insertions occuring before
    for count, insert in enumerate(list_inserts):
        for j in range(count+1, len(list_inserts)):
            if list_inserts[j][0] > insert[0]:
                list_inserts[j][0]-=insert[1]
    # shift inseritions to zero-based space
    for j in range(len(list_inserts)):
        list_inserts[j][0]-=1

    corrected_insert = list_inserts
    corrected_dels =list_dels

    return corrected_insert, corrected_dels

def analyse_position(bamfile, reference, ref_id, position, gap_length, indel_type, gene_list, cons_id='', based=1):
    """
    gather information for current frameshift position.
    """
    gene_region= get_gene_at_position(gene_list, ref_id, position)
    region_start =gene_region[1]
    region_end = gene_region[2]

    #critical_dels = check_dels_gene_region(frameshift_deletions, region_start, region_end, position)

    # TODO cache pysamstats
    variation_info = pysamstats.load_variation_strand(bamfile, fafile= reference,chrom=ref_id,
                                     start=position, end=position+gap_length)
    idx_pos = np.where(variation_info.pos==position)
    if(idx_pos[0].size==0):
        # see MAFFT's BUG mentionned in align()
        print(f"Warning no read mapping to {ref_id}:{position}:+{gap_length}", file=sys.stderr)
        return { } # empty dict

    reads_all = variation_info[idx_pos].reads_all[0]
    reads_fwd = variation_info[idx_pos].reads_fwd[0]
    reads_rev = variation_info[idx_pos].reads_rev[0]

    deletions = variation_info[idx_pos].deletions[0]
    freq_del = deletions/reads_all*100
    deletions_fwd = variation_info[idx_pos].deletions_fwd[0]
    freq_del_fwd = deletions_fwd/reads_fwd*100 if reads_fwd else 0
    deletions_rev = variation_info[idx_pos].deletions_rev[0]
    freq_del_rev = deletions_rev/reads_rev*100 if reads_rev else 0

    insertions = variation_info[idx_pos].insertions[0]
    freq_insert = insertions/reads_all*100
    insertions_fwd = variation_info[idx_pos].insertions_fwd[0]
    freq_insert_fwd = insertions_fwd/reads_fwd*100 if reads_fwd else 0
    insertions_rev = variation_info[idx_pos].insertions_rev[0]
    freq_insert_rev = insertions_rev/reads_rev*100 if reads_rev else 0

    # TODO cache pysamstats
    indels_gene_reg = pysamstats.load_variation_strand(bamfile, fafile=reference,
                                                        chrom=ref_id,
                                                        start=region_start, end=region_end)
    critical_inserts, critical_dels= check_indels_gene_region(indels_gene_reg,position, gap_length, indel_type,
                                                    region_start, region_end, based)

    homopolyeric = check_homopolyeric(variation_info, position, gap_length)

    dict = {'ref_id': ref_id,
            'start_position': position+based,
            'length': gap_length,
            'INDEL': indel_type,
            'gene_region':gene_region[3],
            'reads_all': reads_all,
            'reads_fwd': reads_fwd,
            'reads_rev': reads_rev,
            'deletions': deletions,
            'freq_del': freq_del,
            'freq_del_fwd': freq_del_fwd ,
            'freq_del_rev':freq_del_rev,
            'deletions_fwd': deletions_fwd,
            'deletions_rev': deletions_rev,
            'insertions': insertions,
            'freq_insert': freq_insert,
            'freq_insert_fwd': freq_insert_fwd ,
            'freq_insert_rev':freq_insert_rev,
            'insertions_fwd': insertions_fwd,
            'insertions_rev': insertions_rev,
            'matches_ref': variation_info[idx_pos].matches[0],
            'pos_critical_inserts': critical_inserts,
            'pos_critical_dels': critical_dels,
            'homopolymeric': homopolyeric,
            'ref_base': variation_info[idx_pos].ref[0],
            'cons_id': cons_id,
           }

    return dict

def main():

    args = parse_args()
    bamfile = args.bamfile	    # e.g.: 'REF_aln_410130_171220eg29_H5.bam'
    reference = args.reference	# e.g.: '../references/NC_045512.2.fasta'
    consensus = args.ref_majority_dels	# e.g.: 'ref_majority_dels.fasta'

    gene_list = parse_gff(args.genes_gff) # e.g.: 'Genes_NC_045512.2.GFF3'

    df = pd.DataFrame(columns=('ref_id','start_position','length','INDEL','gene_region',
                                'reads_all','reads_fwd','reads_rev',
                                'deletions','freq_del','freq_del_fwd','freq_del_rev',
                                'deletions_fwd','deletions_rev',
                                'insertions','freq_insert','freq_insert_fwd','freq_insert_rev',
                                'insertions_fwd','insertions_rev',
                                'matches_ref','pos_critical_inserts','pos_critical_dels',
                                'homopolymeric','ref_base','cons_id'))


    align_seqs = align(reference, consensus)
    if (len(align_seqs)==0):
        print("Warning: no usable alignment", file=sys.stderr)
    elif (len(align_seqs)%2!=0):
        print(f"Fatal error: there are {len(align_seqs)} alignements (odd), they should be in pairs (even)!", file=sys.stderr)
        sys.exit(1)
    else:
        align_dels= list_all_dels(align_seqs)
        align_inserts= list_all_inserts(align_seqs)

        # convert coordinate from pair-alignment space to reference-space
        corrected_insert, corrected_dels = correct_positions(align_dels,align_inserts)

        for pos in corrected_dels+corrected_insert:
            ref_id = pos[2]
            position = int(pos[0])
            gap_length = int(pos[1])
            cons_id = pos[3]
            indel_type = pos[4]
            if gap_length%3==0:
                # only frameshift insertions , i.e. insert lenght not dividible by 3
                continue
            pos_dict = analyse_position(bamfile, reference, ref_id, position, gap_length,indel_type,
                                        gene_list,cons_id, based=args.based)
            if (len(pos_dict)==0):
                # skip when no information extracted
                continue
            df = df.append(pos_dict, ignore_index=True)

    df.to_csv(args.outfile)

if __name__ == '__main__':
    main()
